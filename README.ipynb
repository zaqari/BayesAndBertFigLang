{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# A general application of Bayesian & BERT based methods to Metaphor Source Domain Inference\n",
    "\n",
    "This is a linking story. I wanted to show that metaphor source domain comes from . . . somewhere. I wanted to show that just low level linguistic phenomena can account for what we call metaphor. Lots of research in conceptual metaphor has discussed at length how people make sense of metaphor, without first describing how the linguistic form of an utterance can help transmit that metaphoric content. We start by creating a contextual representation of a target term in metaphoric utterance:\n",
    "\n",
    "$$ E_{x,w'} = BERT(x) \\delta_{w=w'} $$\n",
    "\n",
    "I already did this step prior to this markup. So we'll just import those representations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from GovMetaphors.mod.sim_matrix import *\n",
    "soft = nn.Softmax(dim=-1)\n",
    "m = torch.load('GovMetaphors/corpora/GovTweets.pt')\n",
    "\n",
    "CM = m['CM-full']\n",
    "cV = torch.FloatTensor([[np.float(n) for n in vec.replace('[','').replace(']','').split(', ')] for vec in CM['vec'].values])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we get to the magic. We need to find the probability that an embedding $E_{x,w'}$ could come from some other context associated with an embedding $E_{m,w'_m}$. We do this via\n",
    "\n",
    "$$ P(E_{x,w'}|E_{m,w'_m}) = P_{\\mathcal{N}_{[0,\\infty]}} \\left( cosineError(E_{x,w'},E_{m,w'_m}) \\bigg| \\mu=0, \\sigma \\right) $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pi = probFn(.3)\n",
    "P = pi.PROB(cV,cV)\n",
    "r = P"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, these are independent sentences. We need to create metaphor source domain categories. How? Well...\n",
    "\n",
    "$$ P(M|E_{x,w'}) = \\frac{1}{k_M} P(M) \\sum_m P(E_{x,w'}|E_{m,w'_m}) \\delta_{m \\in M} $$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Sentence indeces . . . we use this to exclude the example\n",
    "# given by that row . . . because it'll have a probability\n",
    "# close to 1, and because it's kinda irrelevant for\n",
    "# comparison.\n",
    "cidx = np.array([i for i in range(len(CM))])\n",
    "\n",
    "#Heads up! not every CM tag in our dataset has > 2 examples.\n",
    "# We thus restrict our data to only those CM tags with 2 or\n",
    "# more examples in 'em.\n",
    "good_values = np.array([k for k,v in CM['CM'].value_counts().items() if v > 1])\n",
    "\n",
    "#Implments the equation listed in the last markdown.\n",
    "OUT = torch.FloatTensor([[row[sel([m_],CM['CM'].values) & ~sel([i],cidx)].sum().item() for m_ in good_values] for i,row in enumerate(r)])\n",
    "OUT = OUT * torch.FloatTensor([(sel([m_],CM['CM'].values).sum()/len(sel([m_],CM['CM'].values))) for m_ in good_values]).unsqueeze(0)\n",
    "print(OUT.shape)\n",
    "OUT = OUT/(OUT.sum(dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And finally, we validate (1) precision (with $\\sigma=.3$, .84) and recall (with $\\sigma=.3$, .85)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#(1) Precision\n",
    "PRECISION = np.array([OUT[sel([cm],CM['CM'].values)][:,sel([cm],np.array(good_values))].mean() > OUT[sel([cm],CM['CM'].values)][:,~sel([cm],np.array(good_values))].mean() for cm in good_values]).mean()\n",
    "\n",
    "#(2) Recall\n",
    "RECALL = np.array([OUT[sel([cm],CM['CM'].values)][:,sel([cm],np.array(good_values))].mean() > OUT[~sel([cm],CM['CM'].values)][:,sel([cm],np.array(good_values))].mean() for cm in good_values]).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "and cluster fit (with $\\sigma=.3$, 8.08)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.array([OUT[sel([cm],CM['CM'].values)][:,sel([cm],np.array(good_values))].mean() / OUT[sel([cm],CM['CM'].values)][:,~sel([cm],np.array(good_values))].mean() for cm in good_values]).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Permutation test procedures:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# (1) Randomizing examples (P = 0.0)\n",
    "prec, rec = [],[]\n",
    "for ep in range(1000):\n",
    "    # print('epoch {}/{}'.format(ep+1,1000))\n",
    "    # CMS = np.random.choice(good_values,size=(len(good_values),),replace=False)\n",
    "    ROWS = np.random.choice(CM['CM'].values,size=(len(CM['CM'].values),),replace=False)\n",
    "    prec.append( np.array([OUT[sel([cm],ROWS)][:,sel([cm],good_values)].mean() > OUT[sel([cm],ROWS)][:,~sel([cm],good_values)].mean() for cm in good_values]).mean() )\n",
    "    rec.append( np.array([OUT[sel([cm],ROWS)][:,sel([cm],good_values)].mean() > OUT[~sel([cm],ROWS)][:,sel([cm],good_values)].mean() for cm in good_values]).mean() )\n",
    "prec,rec = np.array(prec), np.array(rec)\n",
    "(PRECISION <= prec).mean(),(RECALL <= rec).mean()\n",
    "\n",
    "\n",
    "\n",
    "# (2) Randomizing CM Source categories (P = 0.0)\n",
    "prec, rec = [],[]\n",
    "for ep in range(1000):\n",
    "    # print('epoch {}/{}'.format(ep+1,1000))\n",
    "    CMS = np.random.choice(good_values,size=(len(good_values),),replace=False)\n",
    "    # ROWS = np.random.choice(CM['CM'].values,size=(len(CM['CM'].values),),replace=False)\n",
    "    prec.append( np.array([OUT[sel([cm],CM['CM'].values)][:,sel([cm],CMS)].mean() > OUT[sel([cm],CM['CM'].values)][:,~sel([cm],CMS)].mean() for cm in CMS]).mean() )\n",
    "    rec.append( np.array([OUT[sel([cm],CM['CM'].values)][:,sel([cm],CMS)].mean() > OUT[~sel([cm],CM['CM'].values)][:,sel([cm],CMS)].mean() for cm in CMS]).mean() )\n",
    "prec,rec = np.array(prec), np.array(rec)\n",
    "(PRECISION <= prec).mean(),(RECALL <= rec).mean()\n",
    "\n",
    "\n",
    "\n",
    "# (3) Randomizing both (P = 0.0)\n",
    "prec, rec = [],[]\n",
    "for ep in range(1000):\n",
    "    # print('epoch {}/{}'.format(ep+1,1000))\n",
    "    CMS = np.random.choice(good_values,size=(len(good_values),),replace=False)\n",
    "    ROWS = np.random.choice(CM['CM'].values,size=(len(CM['CM'].values),),replace=False)\n",
    "    prec.append( np.array([OUT[sel([cm],ROWS)][:,sel([cm],CMS)].mean() > OUT[sel([cm],ROWS)][:,~sel([cm],CMS)].mean() for cm in CMS]).mean() )\n",
    "    rec.append( np.array([OUT[sel([cm],ROWS)][:,sel([cm],CMS)].mean() > OUT[~sel([cm],ROWS)][:,sel([cm],CMS)].mean() for cm in CMS]).mean() )\n",
    "prec,rec = np.array(prec), np.array(rec)\n",
    "(PRECISION <= prec).mean(),(RECALL <= rec).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}